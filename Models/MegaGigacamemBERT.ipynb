{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM5fsDqM5sWq4ALE8EFiHrN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmAmhgdvV4MA","executionInfo":{"status":"ok","timestamp":1701269267725,"user_tz":-60,"elapsed":170928,"user":{"displayName":"laurent Sierro","userId":"01898903540875226616"}},"outputId":"c4f6bbfc-5adf-4296-805c-a14a615bcd7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[4 0 2 1 3 5]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"]}],"source":["#!pip3 install tokenizer\n","#!pip3 install sentencepiece\n","#!pip3 install sentence-transformers\n","import pandas as pd\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from transformers import AdamW\n","from transformers import CamembertTokenizer\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n","from transformers import CamembertForSequenceClassification, CamembertTokenizer\n","from sentence_transformers import SentenceTransformer, util\n","from tqdm import trange\n","import nltk\n","import tokenizer as tokenizer_2\n","import re\n","from nltk.tokenize import word_tokenize\n","import string\n","\n","epochs = 20\n","MAX_LEN = 128\n","batch_size = 8\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load the dataset, I selected only 5000 sample because of memory limitation\n","df = pd.read_csv('training_data_cleaned_length.csv').reset_index(drop=True)\n","df.head()\n","\n","# Mapping des valeurs de la colonne \"difficulty\"\n","difficulty_mapping = {\n","    'A1': 0,\n","    'A2': 1,\n","    'B1': 2,\n","    'B2': 3,\n","    'C1': 4,\n","    'C2': 5\n","}\n","\n","# Utiliser la fonction map pour encoder les valeurs\n","df['difficulty_encoded'] = df['difficulty'].map(difficulty_mapping)\n","\n","unique_labels = df['difficulty_encoded'].unique()\n","print(unique_labels)\n","\n","# Creates list of texts and labels\n","text = df['sentence'].to_list()\n","\n","labels = df['difficulty_encoded'].to_list()  # Utilisez les labels encodés\n","\n","# Utilisez le tokenizer Camembert\n","#tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\", do_lower_case=True)\n","tokenizer = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n","\n","# Utilisez le tokenizer pour convertir les phrases en tokens\n","input_ids = [tokenizer.encode(sent, batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True, convert_to_tensor=False) for sent in text]\n"]},{"cell_type":"code","source":["\n","# Créez des masques d'attention\n","attention_masks = []\n","# Créez un masque de 1 pour chaque token suivi de 0 pour le padding\n","for seq in input_ids:\n","    seq_mask = [float(i > 0) for i in seq]\n","    attention_masks.append(seq_mask)\n"],"metadata":{"id":"ykQSsI40iiLh","executionInfo":{"status":"ok","timestamp":1701269362660,"user_tz":-60,"elapsed":22849,"user":{"displayName":"laurent Sierro","userId":"01898903540875226616"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","    # Convertissez les listes en tenseurs PyTorch\n","print(len(input_ids))\n","input_ids = torch.tensor(input_ids)\n","print(len(input_ids))\n","attention_masks = torch.tensor(attention_masks)\n","labels = torch.tensor(labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCPgmb73jfHd","executionInfo":{"status":"ok","timestamp":1701269427459,"user_tz":-60,"elapsed":2720,"user":{"displayName":"laurent Sierro","userId":"01898903540875226616"}},"outputId":"332f8a0b-938d-48ca-d731-022b82d3d244"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["4800\n","4800\n"]}]},{"cell_type":"code","source":["\n","# Créez un DataLoader pour gérer les lots de données\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","dataloader = DataLoader(dataset, batch_size=batch_size, sampler=RandomSampler(dataset))\n","\n","# Vous pouvez maintenant utiliser dataloader pour l'entraînement de votre modèle.\n","# Use train_test_split to split our data into train and validation sets for training\n","train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n","                                                            random_state=42, test_size=0.2)\n","print(train_inputs.type())\n","\n","# --- Convert all of our data into torch tensors, the required datatype for our model ---\n","# train_inputs = torch.tensor(train_inputs).to(device)\n","# validation_inputs = torch.tensor(validation_inputs).to(device)\n","# train_labels = torch.tensor(train_labels).to(device)\n","# validation_labels = torch.tensor(validation_labels).to(device)\n","# train_masks = torch.tensor(train_masks).to(device)\n","# validation_masks = torch.tensor(validation_masks).to(device)\n","\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n","model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=6)\n","model.to(device)\n","\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","from transformers import AdamW\n","from sklearn.metrics import accuracy_score\n","\n","# Define the optimizer and set the learning rate\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return accuracy_score(labels_flat, pred_flat)\n","\n","from transformers import get_linear_schedule_with_warmup\n","# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n","train_loss_set = []\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","for epoch in range(epochs):\n","    for batch in train_dataloader:\n","        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","\n","        # Perform backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"x40isjLUjzn1","executionInfo":{"status":"error","timestamp":1701270275717,"user_tz":-60,"elapsed":1785,"user":{"displayName":"laurent Sierro","userId":"01898903540875226616"}},"outputId":"151f0915-d93b-4c9b-e6f3-11d69ff92e82"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.FloatTensor\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-cba4e5593407>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1064\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1024) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [8, 1024].  Tensor sizes: [1, 514]"]}]},{"cell_type":"code","source":["\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","    # Tracking variables for training\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    # Train the model\n","    model.train()\n","    for step, batch in enumerate(train_dataloader):\n","        # Add batch to device CPU or GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        print(b_input_ids.type())\n","        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n","        # Get loss value\n","        loss = outputs.loss\n","        # Add it to train loss list\n","        train_loss_set.append(loss.item())\n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","# Update tracking variables\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","    # Tracking variables for validation\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    # Validation of the model\n","    model.eval()\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to device CPU or GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs =  model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n","            logits = outputs.logits\n","\n","        # Move logits and labels to CPU if GPU is used\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","\n","\n","\n","\n","\n"],"metadata":{"id":"7OjLF_3wmlht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Charger le nouveau jeu de données\n","# Remplacez 'new_data.csv' par le chemin de votre fichier de nouvelles phrases\n","new_df = pd.read_csv('unlabelled_test_data_length.csv')\n","new_texts = new_df['sentence'].tolist()  # Assurez-vous que la colonne contient les phrases\n","new_length = new_df['length']\n","# Préparer les données pour le modèle\n","tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n","new_input_ids = [tokenizer.encode(sent, add_special_tokens=True, max_length=MAX_LEN, pad_to_max_length=True, truncation=True) for sent in new_texts]\n","new_attention_masks = [[float(i > 0) for i in seq] for seq in new_input_ids]\n","\n","# Convertir en tenseurs\n","new_input_ids = torch.tensor(new_input_ids)\n","new_input_lgth = torch.tensor(new_length)\n","new_attention_masks = torch.tensor(new_attention_masks)\n","\n","# Créer un DataLoader\n","prediction_data = TensorDataset(new_input_ids, new_input_lgth, new_attention_masks)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","# Prédiction\n","model.eval()\n","predictions = []\n","\n","for batch in prediction_dataloader:\n","    # Ajouter batch à GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_lgth, b_input_mask = batch\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n","\n","    logits = outputs.logits\n","    logits = logits.detach().cpu().numpy()\n","    predictions.append(logits)\n","\n","# Convertir les prédictions en étiquettes de difficulté\n","predicted_labels = [np.argmax(p, axis=1).flatten() for p in predictions]\n","predicted_labels = np.concatenate(predicted_labels)\n","\n","# Créer un DataFrame pour le CSV\n","output_df = pd.DataFrame({\n","    'id': new_df.index,  # ou une autre colonne d'identification si disponible\n","    'difficulty': [list(difficulty_mapping.keys())[list(difficulty_mapping.values()).index(label)] for label in predicted_labels]\n","})\n","\n","# Enregistrer en CSV\n","output_df.to_csv('predicted_difficulties5.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpuM0WLEiZlg","executionInfo":{"status":"ok","timestamp":1701264788563,"user_tz":-60,"elapsed":8689,"user":{"displayName":"laurent Sierro","userId":"01898903540875226616"}},"outputId":"87536309-90d7-4555-c5fd-1a9df5ceb3dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Nouvelle section"],"metadata":{"id":"mIRdP3ZFWdce"}}]}